{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 3 - Classification Models\n",
    "\n",
    "Este es el notebook para la clase o unidad 3, que trata de modelos de clasificación. En particular, revisaremos los modelos K-NN, Naive Bayes, LDA, QDA, SVM y Árboles de clasificación, desde dividir para obtener nuestro set de datos para entrenar y testear, pasando por optimización de parámetros y llegando a medir el desempeño del modelo.\n",
    "\n",
    "Los datos con los que trabajaremos son datos de cancer de mamas, recolectado por la University of Wisconsin Hospitals, Madison, que contiene 699 registros, 10 atributos y la variable target que nos indica si es el tumor es benigno o maligno.\n",
    "\n",
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "breast_data = pd.read_excel('./Data/breast-cancer-wisconsin.xlsx')\n",
    "breast_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_data.Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_data['Class'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos hacer, es dividir nuestros datos para crear el set de train y de test, para esto usamos la función `train_test_split` que viene en `sklearn.model_selection`. Debemos recordar que al K-NN estar basado en distancias, por lo que sería necesario estandarizar o normalizar los datos antes de ponerlos en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#breast_data.drop(['ID'], axis='columns',inplace=True)\n",
    "breast_X =  breast_data.drop(['Class'], axis='columns')\n",
    "breast_y = breast_data['Class']\n",
    "\n",
    "scaler = MinMaxScaler().fit(breast_X)\n",
    "scaled_breast_X = pd.DataFrame(scaler.transform(breast_X), columns=breast_X.columns)\n",
    "scaled_breast_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(breast_X, breast_y, test_size=0.2, stratify = breast_y, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_y.value_counts())\n",
    "display(test_y.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ajustamos el modelo de K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_model.fit(train_X,train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que tal lo hace el modelo, para eso realizaremos predicciones y luego imprimiremos la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pred_values = knn_model.predict(test_X)\n",
    "print(classification_report(test_y,pred_values))\n",
    "print(confusion_matrix(test_y,pred_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = pd.DataFrame(knn_model.predict_proba(test_X),columns = [\"No\",'Si'])\n",
    "probs[\"New_si\"] = np.where(probs[\"Si\"] >= 0.3,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y,probs[\"New_si\"]))\n",
    "print(confusion_matrix(test_y,probs[\"New_si\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos con otro set de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart = pd.read_excel('./Data/Heart.xlsx')\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.dropna(inplace=True)\n",
    "heart_X = heart.drop(['Sex','ChestPain','Thal','AHD'],axis='columns')\n",
    "heart_y = heart['AHD'].replace(('Yes','No'),(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_ahd = MinMaxScaler().fit(heart_X)\n",
    "scaled_heart_df = pd.DataFrame(minmax_ahd.transform(heart_X), columns=heart_X.columns)\n",
    "scaled_heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(heart_X, heart_y, test_size=0.2, stratify=heart_y,random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_ahd = MinMaxScaler().fit(train_X)\n",
    "scaled_heart_train_X = pd.DataFrame(minmax_ahd.transform(train_X), columns=heart_X.columns)\n",
    "scaled_heart_test_X = pd.DataFrame(minmax_ahd.transform(test_X), columns=heart_X.columns)\n",
    "scaled_heart_train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_heart_train_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_heart_test_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "160/(160+137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_model.fit(scaled_heart_train_X,train_y)\n",
    "\n",
    "pred_values = knn_model.predict(scaled_heart_test_X)\n",
    "print(classification_report(test_y,pred_values))\n",
    "print(confusion_matrix(test_y,pred_values))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "veamos qué pasa cuando optimizamos los hiper-parámetros del modelo utilizando `GridSearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors' : [2, 3, 5, 7, 8, 9, 10, 11, 15],\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['euclidean','manhattan']\n",
    "}\n",
    "\n",
    "opt_knn_model = GridSearchCV(KNeighborsClassifier(), \n",
    "                             param_grid = param_grid, \n",
    "                             n_jobs=-1,\n",
    "                             cv = 5,\n",
    "                             scoring = 'accuracy')\n",
    "\n",
    "opt_knn_model.fit(scaled_heart_train_X,train_y)\n",
    "pred_values_knn = opt_knn_model.predict(scaled_heart_test_X)\n",
    "\n",
    "print(opt_knn_model.best_params_)\n",
    "print(opt_knn_model.best_score_)\n",
    "print(classification_report(test_y,pred_values_knn))\n",
    "print(confusion_matrix(test_y,pred_values_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors' : range(2,25),\n",
    "    'weights' : ['uniform','distance'],\n",
    "    'metric' : ['euclidean','manhattan']\n",
    "}\n",
    "\n",
    "opt_knn_model = GridSearchCV(KNeighborsClassifier(), \n",
    "                             param_grid = param_grid, \n",
    "                             n_jobs=-1,\n",
    "                             cv = 5,\n",
    "                             scoring = 'f1')\n",
    "\n",
    "opt_knn_model.fit(scaled_heart_train_X,train_y)\n",
    "pred_values_knn = opt_knn_model.predict(scaled_heart_test_X)\n",
    "\n",
    "print(opt_knn_model.best_params_)\n",
    "print(opt_knn_model.best_score_)\n",
    "print(classification_report(test_y,pred_values_knn))\n",
    "print(confusion_matrix(test_y,pred_values_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=9, metric='manhattan', weights= \"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_knn_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_knn_model.predict_proba(scaled_heart_test_X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Veamos ahora como se desempeña en este último set de datos el modelo de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "naive_model = GaussianNB()\n",
    "naive_model.fit(train_X,train_y)\n",
    "pred_values_nb = naive_model.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y,pred_values_nb))\n",
    "print(confusion_matrix(test_y,pred_values_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hasta el momento\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f\"K-NN: {f1_score(test_y, pred_values_knn)}\")\n",
    "print(f\"Naive Bayes: {f1_score(test_y, pred_values_nb)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n",
    "Es el turno de support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel = 'rbf', C = 1) # C parameter, kernel\n",
    "svm_model.fit(train_X,train_y)\n",
    "pred_values_svm = svm_model.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y,pred_values_svm))\n",
    "print(confusion_matrix(test_y,pred_values_svm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arreglemos un poquito más el modelo de SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'degree' : [2,3],\n",
    "    'kernel' : ['linear','rbf'],\n",
    "    'C' : [0.01,0.1,1,10,100]\n",
    "}\n",
    "\n",
    "opt_svm_model = GridSearchCV(SVC(), \n",
    "                             param_grid = param_grid, \n",
    "                             cv = 5, \n",
    "                             n_jobs = -1,\n",
    "                             scoring = \"f1\")\n",
    "\n",
    "opt_svm_model.fit(train_X,train_y)\n",
    "pred_values_osvm = opt_svm_model.predict(test_X)\n",
    "\n",
    "print(opt_svm_model.best_params_)\n",
    "print(classification_report(test_y,pred_values_osvm))\n",
    "print(confusion_matrix(test_y,pred_values_osvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hasta el momento\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f\"K-NN: {f1_score(test_y, pred_values_knn)}\")\n",
    "print(f\"Naive Bayes: {f1_score(test_y, pred_values_nb)}\")\n",
    "print(f\"SVM: {f1_score(test_y, pred_values_osvm)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "tree_model = DecisionTreeClassifier(max_depth=4, min_samples_leaf=8)\n",
    "tree_model.fit(train_X, train_y)\n",
    "pred_values_tree = tree_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(test_y,pred_values_tree))\n",
    "print(confusion_matrix(test_y,pred_values_tree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revisemos como es el árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "features = heart_X.columns\n",
    "classes = ['Not heart disease','heart disease']\n",
    "plot_tree(tree_model,feature_names=features,class_names=classes,filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model.feature_names_in_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos hacer este árbol un poco mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'max_depth': [2,4,6,8,10,12],\n",
    "         'min_samples_split': [5,10,15,20],\n",
    "         'min_samples_leaf': [5,10,15,20]}\n",
    "\n",
    "opt_tree_model = GridSearchCV(DecisionTreeClassifier(),param_grid=params, cv = 5, n_jobs=-1)\n",
    "opt_tree_model.fit(train_X,train_y)\n",
    "pred_values_otree = opt_tree_model.predict(test_X)\n",
    "\n",
    "print(opt_tree_model.best_params_)\n",
    "print(classification_report(test_y,pred_values_otree))\n",
    "print(confusion_matrix(test_y,pred_values_otree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "veamos como queda el árbol ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_model = opt_tree_model.best_estimator_\n",
    "best_tree_model.fit(train_X,train_y)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "features = heart.columns\n",
    "classes = ['Not heart disease','heart disease']\n",
    "plot_tree(best_tree_model,feature_names=features,class_names=classes,filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hicimos antes, limitando la profundidad máxima del árbol nos permite evitar el sobre-ajuste y obtener mejores predicciones. Pero existe otro parámetro de en los árboles llamado `cp`, que tiene que ver con la complejidad del modelo y podemos también hacer un tuning con él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_model = DecisionTreeClassifier()\n",
    "path = tree_model.cost_complexity_pruning_path(train_X, train_y)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "print(ccp_alphas[:-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "luego, ajustamos modelos para cada uno de los valores anteriores y los guardamos en una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for ccp_alpha in ccp_alphas[:-1]:\n",
    "    model = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    model.fit(train_X, train_y)\n",
    "    models.append(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finalmente, calculamos el accuracy para cada modelo en el set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []\n",
    "for c in models:\n",
    "    test_pred = c.predict(test_X)\n",
    "    test_acc.append(accuracy_score(test_pred,test_y))\n",
    "\n",
    "plt.scatter(ccp_alphas[:-1],test_acc)\n",
    "plt.plot(ccp_alphas[:-1],test_acc,label='test_accuracy',drawstyle=\"steps-post\")\n",
    "plt.title('Accuracy vs alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': [2,4,6,8,10,12],\n",
    "         'min_samples_split': [5,10,15,20],\n",
    "         'min_samples_leaf': [5,10,15,20]}\n",
    "\n",
    "opt_tree_model = GridSearchCV(DecisionTreeClassifier(ccp_alpha=0.01514514),param_grid=params,cv = 5, n_jobs=-1)\n",
    "opt_tree_model.fit(train_X,train_y)\n",
    "pred_values_otree = opt_tree_model.predict(test_X)\n",
    "\n",
    "print(opt_tree_model.best_params_)\n",
    "print(classification_report(test_y,pred_values_otree))\n",
    "print(confusion_matrix(test_y,pred_values_otree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "también podriamos hacerlo directamente con el GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'ccp_alpha': ccp_alphas[:-1],\n",
    "         'max_depth': [2,4,6,8,10,12],\n",
    "         'min_samples_split': [5,10,15,20],\n",
    "         'min_samples_leaf': [5,10,15,20]}\n",
    "\n",
    "opt_tree_model = GridSearchCV(DecisionTreeClassifier(),param_grid=params, cv = 5, n_jobs=-1)\n",
    "opt_tree_model.fit(train_X,train_y)\n",
    "pred_values_otree = opt_tree_model.predict(test_X)\n",
    "\n",
    "print(opt_tree_model.best_params_)\n",
    "print(classification_report(test_y,pred_values_otree))\n",
    "print(confusion_matrix(test_y,pred_values_otree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hasta el momento\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f\"K-NN: {f1_score(test_y, pred_values_knn)}\")\n",
    "print(f\"Naive Bayes: {f1_score(test_y, pred_values_nb)}\")\n",
    "print(f\"SVM: {f1_score(test_y, pred_values_osvm)}\")\n",
    "print(f\"Tree: {f1_score(test_y, pred_values_otree)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.arff as arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff(open('./Data/Rice_Cammeo_Osmancik.arff','rt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(data[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.arff as arff\n",
    "import pandas as pd\n",
    "\n",
    "data = arff.loadarff(open('FILE_PATH','rt'))\n",
    "df = pd.DataFrame(data[0])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
